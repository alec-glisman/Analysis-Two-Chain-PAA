{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch sklearn\n",
    "from sklearnex import patch_sklearn\n",
    "\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# standard libraries\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# third party libraries\n",
    "import cmasher as cmr\n",
    "import corner\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Jupyter display\n",
    "from IPython.display import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from torchviz import make_dot\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add local libraries to path\n",
    "sys.path.append(str(Path.cwd().parents[3] / \"src\"))\n",
    "\n",
    "# local libraries\n",
    "from figures.style import set_style  # noqa: E402\n",
    "set_style()  # noqa: E402\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find hardware or use cpu\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data loading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def natural_sort(l: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Sorts a list of strings naturally (i.e. 1, 2, 3, 10, 11, 12, etc.)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    l : list[str]\n",
    "        List of strings to sort\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[str]\n",
    "        Sorted list of strings\n",
    "    \"\"\"\n",
    "\n",
    "    def convert(text: str):\n",
    "        \"\"\"\n",
    "        Converts text to integers if possible. If not, converts to lowercase.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : str\n",
    "            Text to convert\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int or str\n",
    "            Converted text\n",
    "        \"\"\"\n",
    "        if text.isdigit():\n",
    "            return int(text)\n",
    "        else:\n",
    "            return text.lower()\n",
    "\n",
    "    def alphanum_key(key: str) -> list[str]:\n",
    "        \"\"\"\n",
    "        Splits the key into a list of strings and integers.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        key : str\n",
    "            Key to split\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list[str]\n",
    "            List of strings and integers\n",
    "        \"\"\"\n",
    "        if not isinstance(key, str):\n",
    "            key = str(key)\n",
    "        return [convert(c) for c in re.split(\"([0-9]+)\", key)]\n",
    "\n",
    "    return sorted(l, key=alphanum_key)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data source information\n",
    "n_ca: int = 32\n",
    "pattern_data: str = \"features_2PAcr*.npz\"\n",
    "dir_base: Path = Path(\"/media/aglisman/Linux_Overflow/home/aglisman/VSCodeProjects/Gromacs-Data-Analysis/analysis/16-paper-2chain-analysis/notebooks/polymer_conformation/output/data_generation/data\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find data\n",
    "files_data: list = natural_sort(list(dir_base.glob(pattern_data)))\n",
    "print(f\"Found {len(files_data)} data files\")\n",
    "print(*files_data, sep=\"\\n\")\n",
    "\n",
    "# pick file with pattern {n_ca}Ca\n",
    "idx_sim: int = 0\n",
    "for idx, file in enumerate(files_data):\n",
    "    if f\"{n_ca}Ca\" in file.stem:\n",
    "        idx_sim = idx\n",
    "        break\n",
    "\n",
    "# load arrays\n",
    "print(f\"Loading data from {files_data[idx_sim].stem}\")\n",
    "np_data = np.load(files_data[idx_sim])\n",
    "data = np_data[\"features_scaled\"]\n",
    "labels = np_data[\"labels\"]\n",
    "\n",
    "# create dataframes\n",
    "features = pd.DataFrame(np_data[\"features_scaled\"], columns=np_data[\"labels\"])\n",
    "features_unscaled = pd.DataFrame(np_data[\"features\"], columns=np_data[\"labels\"])\n",
    "dynamics = pd.DataFrame({\n",
    "    \"frame\": np_data[\"frames\"],\n",
    "    \"time\": np_data[\"times\"],\n",
    "    \"weight\": np_data[\"weights\"],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New CV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data source information\n",
    "file_type: str = [\"C_alpha_linear\", \"carboxy_C_linear\"]\n",
    "feats = file_type[0]\n",
    "pattern_data: str = f\"**/contact_matrix_*{feats}.parquet\"\n",
    "dir_base: Path = Path(\"/media/aglisman/Linux_Overflow/home/aglisman/VSCodeProjects/Gromacs-Data-Analysis/analysis/16-paper-2chain-analysis/data/mdanalysis/output_pairdist\")\n",
    "\n",
    "# find data\n",
    "files_data: list = natural_sort(list(dir_base.glob(pattern_data)))\n",
    "print(f\"Found {len(files_data)} files\")\n",
    "\n",
    "# pick file with pattern {n_ca}Ca\n",
    "idx_sim: int = 0\n",
    "for idx, file in enumerate(files_data):\n",
    "    if f\"{n_ca}_Ca\" in file.stem:\n",
    "        idx_sim = idx\n",
    "        break\n",
    "\n",
    "print(f\"Loading data from {files_data[idx_sim].stem}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load parquet file into dataframe\n",
    "df_pairdist = pd.read_parquet(files_data[idx_sim])\n",
    "df_d12 = df_pairdist[[\"time\",\"frame\",\"d12\", \"weight\"]].copy()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patterns = []\n",
    "\n",
    "# drop all columns with pattern \"psi_\"\n",
    "# patterns.append(\"psi_\")\n",
    "# drop columns with pattern \"phi_\"\n",
    "# patterns.append(\"phi_\") \n",
    "\n",
    "# drop all columns with pattern \"CN_Ca_\"\n",
    "# patterns.append(\"CN_Ca_\")\n",
    "# drop all columns with pattern \"CN_Calpha_\"\n",
    "# patterns.append(\"CN_Calpha_\")\n",
    "\n",
    "# drop columns with pattern \"Rg_\" or \"d12\"\n",
    "# patterns.append(\"Rg_\")\n",
    "# patterns.append(\"d12\")\n",
    "\n",
    "# features = features.loc[:, ~features.columns.str.contains(\"|\".join(patterns))]\n",
    "\n",
    "print(f\"Data shape: {features.shape}\")\n",
    "print(f\"Remaining features: {features.columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_pairdist.filter(regex=\"ag1_\").describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out rows where d12 is outside of range\n",
    "d12_range = (0.69034517, 1.06853427) # FIXME: hard-coded\n",
    "# d12_range = (0.0, 4.0) # FIXME: hard-coded\n",
    "df_pairdist = df_pairdist.loc[(df_pairdist[\"d12\"] >= d12_range[0]) & (df_pairdist[\"d12\"] <= d12_range[1])]\n",
    "\n",
    "# filter columns with pattern \"ag1_\"\n",
    "pairdist = df_pairdist.filter(regex=\"ag1_\")\n",
    "print(f\"Loaded {pairdist.shape[0]} rows and {pairdist.shape[1]} columns\")\n",
    "print(f\"Columns: {list(pairdist.columns)}\")\n",
    "\n",
    "# make numpy array of shape (n_samples, n_ag1, n_ag2)\n",
    "n_sample: int = pairdist.shape[0]\n",
    "n_ag1: int = int(np.sqrt(pairdist.shape[1]))\n",
    "pairdist_matrix = np.zeros((n_sample, n_ag1, n_ag1))\n",
    "\n",
    "# reshape each row into a matrix\n",
    "for idx, row in enumerate(pairdist.values):\n",
    "    pairdist_matrix[idx] = row.reshape(n_ag1, n_ag1)\n",
    "print(f\"Pairdist matrix shape: {pairdist_matrix.shape}\")\n",
    "print(f\"Pairdist matrix 0\")\n",
    "\n",
    "# create array from upper triangular matrix of shape (n_samples, n_ag1 * (n_ag1 - 1) / 2)\n",
    "pairdist_upper = np.zeros((n_sample, int(n_ag1 * (n_ag1 - 1) / 2)))\n",
    "for idx, sample in enumerate(pairdist_matrix):\n",
    "    pairdist_upper[idx] = sample[np.triu_indices(n_ag1, k=1)].flatten()\n",
    "print(f\"Pairdist upper array shape: {pairdist_upper.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify pairdist matrix is symmetric\n",
    "for idx, sample in enumerate(pairdist_matrix):\n",
    "    if not np.allclose(sample, sample.T):\n",
    "        print(f\"Sample {idx} is not symmetric\")\n",
    "\n",
    "# check upper triangular matrix has no zeros or NaNs\n",
    "if np.any(pairdist_upper == 0):\n",
    "    print(\"Pairdist upper array has zeros\")\n",
    "\n",
    "print(f\"Pairdist max value: {np.max(pairdist_upper)}\")\n",
    "print(f\"Pairdist min value: {np.min(pairdist_upper)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather data\n",
    "dataset = pairdist_upper.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "percent_train: float = 0.8\n",
    "seed: int = 42\n",
    "batch_size: int = 256\n",
    "num_threads: int = 16\n",
    "num_epochs: int = 1000\n",
    "num_epoch_dump: int = 25\n",
    "num_features: int = dataset.shape[1]\n",
    "\n",
    "variational: bool = False\n",
    "verbose: bool = True\n",
    "\n",
    "learning_rate: float = 1e-3\n",
    "weight_l2_regular: float = 1e-5\n",
    "weight_kld_loss: float = 1e0\n",
    "weight_recons_loss: float = 1e0\n",
    "\n",
    "dim_latent: int = 2\n",
    "dim_feature: int = num_features\n",
    "dim_hidden: list[int] = [num_features, 128, 32]\n",
    "\n",
    "sample_input = torch.randn(1, dim_feature).to(device).double()\n",
    "dims = \"_\".join([str(x) for x in dim_hidden])\n",
    "tag = (\n",
    "    f\"{feats}-DI_{dim_feature}-DH_{dims}-DL_{dim_latent}\"\n",
    "    + f\"-WK_{weight_kld_loss}-WR_{weight_recons_loss}\"\n",
    "    + f\"-LR_{learning_rate}-RG_{weight_l2_regular}-BS_{batch_size}-SD_{seed}\"\n",
    "    + f\"-VA_{variational}-d12_{d12_range[0]}_{d12_range[1]}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# set data types\n",
    "torch.set_default_dtype(torch.float64)\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output directories\n",
    "dir_out = Path.cwd() / \"output_pairdist\" / tag\n",
    "\n",
    "dir_models = dir_out / \"models\"\n",
    "dir_figures = dir_out / \"figures\" \n",
    "dir_runs = dir_out / \"runs\"\n",
    "\n",
    "for d in [dir_models, dir_figures, dir_runs]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "dataset_min = np.nanmin(dataset)\n",
    "dataset_max = np.nanmax(dataset)\n",
    "dataset = (dataset - dataset_min) / (dataset_max - dataset_min)\n",
    "\n",
    "# verify normalization\n",
    "assert np.nanmin(dataset) == 0.0\n",
    "assert np.nanmax(dataset) == 1.0\n",
    "\n",
    "# verify no NaN/inf\n",
    "assert not np.isnan(dataset).any()\n",
    "assert not np.isinf(dataset).any()\n",
    "\n",
    "# convert to tensor\n",
    "dataset = torch.from_numpy(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train and validation sets\n",
    "train_size = int(percent_train * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_features, valid_features = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# get indices for each set (for plotting)\n",
    "train_indices = np.array(train_features.indices)\n",
    "valid_indices = np.array(valid_features.indices)\n",
    "\n",
    "print(f\"Shape of dataset: {dataset.size()}\")\n",
    "print(f\"Training set size: {len(train_features)}\")\n",
    "print(f\"Validation set size: {len(valid_features)}\")\n",
    "\n",
    "print(f\"Training set indices: {train_indices}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "kwargs = {\"num_workers\": num_threads, \"batch_size\": batch_size, \"shuffle\": True}\n",
    "if device == torch.device(\"cuda\"):\n",
    "    kwargs[\"pin_memory\"] = True\n",
    "\n",
    "train_loader = DataLoader(train_features, **kwargs)\n",
    "valid_loader = DataLoader(valid_features, **kwargs)\n",
    "all_loader = DataLoader(dataset, **kwargs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Tag: {tag}\")\n",
    "print()\n",
    "print(f\"Number of data points: {len(dataset)}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print()\n",
    "print(f\"Feature dimension: {dim_feature}\")\n",
    "print(f\"Hidden dimension: {dim_hidden}\")\n",
    "print(f\"Latent dimension: {dim_latent}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        k_loss_kld: float = 1.0,\n",
    "        k_loss_recons: float = 1.0,\n",
    "        input_dim: int = 32,\n",
    "        latent_dim: int = 2,\n",
    "        hidden_dims: list[int] = None,\n",
    "        variational: bool = False,\n",
    "        verbose: bool = False,\n",
    "    ):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # class logger\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.stream_handler = logging.StreamHandler()\n",
    "        self.formatter = logging.Formatter(\n",
    "            \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    "        )\n",
    "        self.stream_handler.setFormatter(self.formatter)\n",
    "        self.logger.addHandler(self.stream_handler)\n",
    "        self.logger.setLevel(logging.DEBUG if verbose else logging.INFO)\n",
    "\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [128, 32]\n",
    "\n",
    "        # layer dimensions\n",
    "        self.layer_dims = [input_dim] + hidden_dims + [latent_dim]\n",
    "        self.logger.debug(f\"Layer dimensions: {self.layer_dims}\")\n",
    "\n",
    "        # layer functions\n",
    "        self.layer_func = nn.Linear\n",
    "        self.activation_func = nn.Tanh\n",
    "        self.variational = variational\n",
    "\n",
    "        # build encoder\n",
    "        modules = []\n",
    "        if variational:\n",
    "            self.encoder_dims = [input_dim] + hidden_dims\n",
    "        else:\n",
    "            self.encoder_dims = [input_dim] + hidden_dims + [latent_dim]\n",
    "        self.logger.info(f\"Building encoder with {len(self.encoder_dims)} layers of size {self.encoder_dims}\")\n",
    "        for i in range(len(self.encoder_dims) - 1):\n",
    "            self.logger.debug(f\"Adding layer {i}: {self.encoder_dims[i]} -> {self.encoder_dims[i + 1]}\")\n",
    "            modules.append([\n",
    "                    self.layer_func(self.encoder_dims[i], self.encoder_dims[i + 1], dtype=torch.float64),\n",
    "                    self.activation_func(),\n",
    "                ])\n",
    "        modules = [item for sublist in modules for item in sublist]\n",
    "        self._encode = nn.Sequential(*modules)\n",
    "        # initialize weights\n",
    "        for i in range(len(self._encode)):\n",
    "            self._encode[i].apply(self._init_weights)\n",
    "\n",
    "        # build variational (latent) layers\n",
    "        self.logger.info(f\"Building variational layers of dimension ({hidden_dims[-1]}, {latent_dim})\")\n",
    "        self.fc_mu = self.layer_func(hidden_dims[-1], latent_dim, dtype=torch.float64)\n",
    "        self.fc_var = self.layer_func(hidden_dims[-1], latent_dim, dtype=torch.float64)\n",
    "        # initialize weights\n",
    "        self.fc_mu.apply(self._init_weights)\n",
    "        self.fc_var.apply(self._init_weights)\n",
    "\n",
    "        # decoder layers: fully connected layers\n",
    "        self.decoder_dims = [latent_dim] + hidden_dims[::-1] + [input_dim]\n",
    "        self.logger.info(f\"Building decoder with {len(self.decoder_dims)} layers of size {self.decoder_dims}\")\n",
    "        modules = []\n",
    "        for i in range(len(self.decoder_dims) - 1):\n",
    "            self.logger.debug(f\"Adding layer {i}: {self.decoder_dims[i]} -> {self.decoder_dims[i + 1]}\")\n",
    "            modules.append([\n",
    "                    self.layer_func(self.decoder_dims[i], self.decoder_dims[i + 1], dtype=torch.float64),\n",
    "                    self.activation_func(),\n",
    "            ])\n",
    "        # add sigmoid activation to last layer\n",
    "        modules.append([nn.Sigmoid()])\n",
    "        modules = [item for sublist in modules for item in sublist]\n",
    "        self._decode = nn.Sequential(*modules)\n",
    "        # initialize weights\n",
    "        for i in range(len(self._decode)):\n",
    "            self._decode[i].apply(self._init_weights)\n",
    "\n",
    "        # latent space information\n",
    "        self.z = None\n",
    "        self.mu = None\n",
    "        self.logvar = None\n",
    "        self.sigma = None\n",
    "\n",
    "        # loss weights\n",
    "        self.k_loss_kld = k_loss_kld\n",
    "        self.k_loss_recons = k_loss_recons\n",
    "\n",
    "        # metrics\n",
    "        self.loss = 0.\n",
    "        self.recons_loss = 0.\n",
    "        self.kld_loss = 0.\n",
    "        self.kld = 0.\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            module.bias.data.fill_(0.01)\n",
    "            self.logger.info(f\"Initialized weights\")\n",
    "        else:\n",
    "            self.logger.info(f\"Skipped initialization of weights: {module}\")\n",
    "        \n",
    "\n",
    "    def encoder(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.to(device)\n",
    "        y = torch.empty((self.encoder_dims[-1]), dtype=torch.float64)\n",
    "        y = self._encode(x)\n",
    "\n",
    "        if self.variational:\n",
    "            z = self.reparametrize(y)\n",
    "        else:\n",
    "            z = y\n",
    "\n",
    "        return z\n",
    "\n",
    "    def bottleneck(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.to(device)\n",
    "        z = self.activation_func(self.fc_mu(x))\n",
    "        return z\n",
    "    \n",
    "    def reparametrize(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        x = x.to(device)\n",
    "\n",
    "        # variational layer (latent space)\n",
    "        self.mu =  self.fc_mu(x)  # mean\n",
    "        self.logvar = self.fc_var(x)  # log variance\n",
    "        self.sigma = torch.exp(0.5 * self.logvar)  # standard deviation\n",
    "        self.epsilon = torch.randn_like(self.sigma) # gaussian noise N(0, 1)\n",
    "        # kl divergence\n",
    "        self.kld = self.kl_divergence()\n",
    "\n",
    "        # reparameterization via sampling from normal distribution\n",
    "        z = self.mu + self.sigma * self.epsilon\n",
    "        return z\n",
    "    \n",
    "    def kl_divergence(self) -> torch.Tensor:\n",
    "        if not self.variational:\n",
    "            return 0.\n",
    "        return -0.5 * torch.sum(1 + self.logvar - self.mu**2 - torch.exp(self.logvar))\n",
    "\n",
    "    def decoder(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        z = z.to(device)\n",
    "        z = self._decode(z)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.to(device)\n",
    "        z = self.encoder(x)\n",
    "        xhat = self.decoder(z)\n",
    "        return xhat\n",
    "    \n",
    "    def loss_function(self, x: torch.Tensor, x_hat: torch.Tensor) \\\n",
    "        -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        x = x.to(device)\n",
    "        x_hat = x_hat.to(device)\n",
    "        \n",
    "        # reconstruction loss: mean squared error\n",
    "        self.recons_loss = self.k_loss_recons * F.mse_loss(x_hat, x, reduction=\"mean\")\n",
    "\n",
    "        # kl divergence loss\n",
    "        self.kld_loss = self.k_loss_kld * self.kl_divergence() / x.shape[0]\n",
    "\n",
    "        # total loss\n",
    "        self.loss = self.recons_loss + self.kld_loss\n",
    "\n",
    "        return self.loss, self.recons_loss, self.kld_loss\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create models\n",
    "model = Autoencoder(\n",
    "    k_loss_kld=weight_kld_loss,\n",
    "    k_loss_recons=weight_recons_loss,\n",
    "    latent_dim=dim_latent,\n",
    "    input_dim=dim_feature,\n",
    "    hidden_dims=dim_hidden,\n",
    "    variational=variational,\n",
    "    verbose=verbose,\n",
    "    )\n",
    "optim = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    "    weight_decay=weight_l2_regular,\n",
    "    )\n",
    "\n",
    "# move to GPU\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print summary\n",
    "fname = f\"{dir_models}/model_summary_{tag}.txt\"\n",
    "text = summary(\n",
    "    model,\n",
    "    input_size=sample_input.size(),\n",
    "    device=device.type,\n",
    "    dtypes=[torch.float64],\n",
    ")\n",
    "\n",
    "with open(fname, \"w\") as f:\n",
    "    print(text, file=f)\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make image of network\n",
    "graph = make_dot(\n",
    "    model(sample_input),\n",
    "    params=dict(model.named_parameters()),\n",
    "    show_attrs=False,\n",
    "    show_saved=True,\n",
    ")\n",
    "\n",
    "# save graph\n",
    "fname = f\"{dir_models}/model_network_{tag}\"\n",
    "graph.format = \"png\"\n",
    "graph.render(fname)\n",
    "\n",
    "# delete temporary file\n",
    "os.remove(f\"{fname}\")\n",
    "\n",
    "# show graph\n",
    "Image(f\"{fname}.{graph.format}\", width=600)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training function\n",
    "def train_epoch(vae, device, dataloader, optimizer):\n",
    "    \n",
    "    # Set train mode for both the encoder and the decoder\n",
    "    vae.train()\n",
    "    train_loss, recons_loss, kld_loss = 0.0, 0.0, 0.0\n",
    "    \n",
    "    # Iterate the dataloader\n",
    "    for x in dataloader: \n",
    "        # Evaluate loss\n",
    "        x = x.to(device)\n",
    "        x_hat = vae(x)\n",
    "        loss, recons, kld = vae.loss_function(x, x_hat)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        recons_loss += recons.item()\n",
    "        if vae.variational:\n",
    "            kld_loss += kld.item()\n",
    "    \n",
    "    # Return loss\n",
    "    loss = train_loss / len(dataloader.dataset)\n",
    "    recons_loss = recons_loss / len(dataloader.dataset)\n",
    "    kld_loss = kld_loss / len(dataloader.dataset)\n",
    "    return loss, recons_loss, kld_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing function\n",
    "def test_epoch(vae, device, dataloader, verbose=False):\n",
    "    \n",
    "    # Set evaluation mode for encoder and decoder\n",
    "    vae.eval()\n",
    "    val_loss, recons_loss, kld_loss = 0.0, 0.0, 0.0\n",
    "    \n",
    "    with torch.no_grad(): # No need to track the gradients\n",
    "        for x in dataloader:\n",
    "            x = x.to(device)\n",
    "            x_hat = vae(x)\n",
    "            loss, recons, kld  = vae.loss_function(x, x_hat)\n",
    "            val_loss += loss.item()\n",
    "            recons_loss += recons.item()\n",
    "            if vae.variational:\n",
    "                kld_loss += kld.item()\n",
    "\n",
    "        val_loss /= len(dataloader.dataset)\n",
    "        recons_loss /= len(dataloader.dataset)\n",
    "        kld_loss /= len(dataloader.dataset)\n",
    "\n",
    "        if verbose:\n",
    "                print(f\"Loss Validation, Reconstruction, KL: ({val_loss:.4e}, {recons_loss:.4e}, {kld_loss:.4e})\")\n",
    "\n",
    "    return val_loss, recons_loss, kld_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent(network, data, epoch, tag, perplexity=30, n_iter=300):\n",
    "    cmap = cmr.take_cmap_colors(\"cmr.rainforest\", 10, cmap_range=(0.1, 0.9))\n",
    "    fname = f\"{dir_figures}/latent-{tag}-epoch_{epoch}\"\n",
    "\n",
    "    # iterate over data loader to get all data\n",
    "    dat = []\n",
    "    for i, data in enumerate(data):\n",
    "        dat.append(data)\n",
    "    dat = torch.cat(dat)\n",
    "    z = network.encoder(dat.to(device))\n",
    "    z = z.to('cpu').detach().numpy()\n",
    "\n",
    "    # if number of dimensions (columns) is greater than 2, use t-SN\n",
    "    title = f\"Latent Space (Epoch {epoch})\"\n",
    "    if z.shape[1] > 2:\n",
    "        title = f\"Latent Space (Epoch {epoch}; t-SNE)\"\n",
    "        fname += f\"-tsne_p{perplexity}_n{n_iter}\"\n",
    "        mod = TSNE(n_components=2, perplexity=perplexity, n_iter=n_iter)\n",
    "        z = mod.fit_transform(z)\n",
    "        print(f\"Final t-SNE KL divergence: {mod.kl_divergence_:.4f}\")\n",
    "    \n",
    "    # plot latent space data\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(z[:, 0], z[:, 1], color=cmap[1], alpha=0.7, linestyle=\"\", marker=\"o\", markersize=2)\n",
    "    ax.set_xlabel(r\"$z_1$\")\n",
    "    ax.set_ylabel(r\"$z_2$\")\n",
    "    ax.set_title(title, y=1.02)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"{fname}.png\", dpi=300)\n",
    "\n",
    "    # calculate 2D KDE\n",
    "    xmin, ymin = z[:, 0].min(), z[:, 1].min()\n",
    "    xmax, ymax = z[:, 0].max(), z[:, 1].max()\n",
    "    xx, yy = np.mgrid[xmin:xmax:250j, ymin:ymax:250j]\n",
    "    positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "    values = np.vstack([z[:, 0], z[:, 1]])\n",
    "    kernel = stats.gaussian_kde(values, bw_method=0.04/values.std())\n",
    "    pdf = kernel(positions).reshape(xx.shape)\n",
    "    pdf /= pdf.sum()\n",
    "\n",
    "    # plot latent space PDF\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    im = ax.imshow(\n",
    "        pdf.T,\n",
    "        origin=\"lower\",\n",
    "        aspect=\"auto\",\n",
    "        extent=[xmin, xmax, ymin, ymax],\n",
    "        cmap=cmr.get_sub_cmap(\"cmr.rainforest\", 0.1, 0.9),\n",
    "    )\n",
    "\n",
    "    fig.colorbar(im, ax=ax, label=r\"Probability Density\")\n",
    "    ax.set_xlabel(f\"$t_1$\")\n",
    "    ax.set_ylabel(f\"$t_2$\")\n",
    "    ax.set_title(\"Latent Space\", y=1.02)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"{fname}_pdf.png\", dpi=300)\n",
    "\n",
    "    # plot fes\n",
    "    fes = -np.log(pdf)\n",
    "    fes -= fes.min()\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(\n",
    "        fes.T,\n",
    "        cmap=cmr.get_sub_cmap(\"cmr.rainforest_r\", 0.1, 0.80),\n",
    "        extent=[xmin, xmax, ymin, ymax],\n",
    "        origin=\"lower\",\n",
    "        aspect=\"auto\",\n",
    "        vmin=0,\n",
    "        vmax=6,\n",
    "    )\n",
    "    # add contours\n",
    "    levels = [1, 2, 3]\n",
    "    line_colors = [\"white\" for l in levels]\n",
    "    label_colors = [\"white\" for l in levels]\n",
    "    cp = ax.contour(xx, yy, fes, levels=levels, colors=line_colors, linewidths=1)\n",
    "    cl = ax.clabel(cp, fontsize=15, colors=label_colors)\n",
    "    # add colorbar\n",
    "    fig.colorbar(im, ax=ax, label=r\"$\\Delta F$ [$k_{B}\\, T$]\")\n",
    "    ax.set_xlabel(f\"$t_1$\")\n",
    "    ax.set_ylabel(f\"$t_2$\")\n",
    "    ax.set_title(\"Latent Space\", y=1.02)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"{fname}_fes.png\", dpi=300)\n",
    "\n",
    "\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ae_outputs(autoencoder, epoch, tag, n=5):\n",
    "    \n",
    "    fig = plt.figure(figsize=(11, 6))\n",
    "    axs = fig.subplots(3, n+1)\n",
    "    fname = f\"{dir_figures}/ae_outputs-{tag}-epoch_{epoch}\"\n",
    "\n",
    "    fig.suptitle(f\"Epoch {epoch}\", fontsize=40, fontweight=\"bold\")\n",
    "    \n",
    "    for i in range(n):\n",
    "        img = train_features[i]\n",
    "        with torch.no_grad():\n",
    "            rec_img  = autoencoder(img.to(device))\n",
    "        # convert tensors to 1D numpy arrays\n",
    "        img_cpu = img.cpu().numpy()\n",
    "        rec_img_cpu = rec_img.cpu().numpy()\n",
    "\n",
    "        # pad tensors to be length of perfect square\n",
    "        num_square = int(np.ceil(np.sqrt(img_cpu.shape[0])))\n",
    "        num_add = num_square**2 - img_cpu.shape[0]\n",
    "        img_cpu = np.pad(img_cpu, (0,num_add), mode='constant', constant_values=0)\n",
    "        rec_img_cpu = np.pad(rec_img_cpu, (0,num_add), mode='constant', constant_values=0)\n",
    "\n",
    "        # convert 1D arrays to 2d square arrays with 0 for empty space\n",
    "        img_cpu = np.reshape(img_cpu, (num_square, num_square))\n",
    "        rec_img_cpu = np.reshape(rec_img_cpu, (num_square, num_square))\n",
    "\n",
    "        # difference between original and reconstructed\n",
    "        diff = img_cpu - rec_img_cpu\n",
    "\n",
    "        # add figures to plot\n",
    "        im0 = axs[0, i].imshow(diff, cmap=cmr.fusion, vmin=-0.2, vmax=0.2)\n",
    "        im1 = axs[1, i].imshow(img_cpu, cmap=cmr.lilac, vmin=0, vmax=1)\n",
    "        im2 = axs[2, i].imshow(rec_img_cpu, cmap=cmr.lilac, vmin=0, vmax=1)\n",
    "\n",
    "        # plot elements\n",
    "        titles = [\"Difference\", \"Original\", \"Reconstructed\"]\n",
    "        for j in range(3):\n",
    "            ax = axs[j, i]\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            if i == n//2:\n",
    "                ax.set_title(titles[j])\n",
    "        \n",
    "        # add colorbar and remove axes on last column\n",
    "        if i == n-1:\n",
    "            ims = [im0, im1, im2]\n",
    "            for j in range(3):\n",
    "                ax = axs[j, -1]\n",
    "                ax.axis('off')\n",
    "                fig.colorbar(ims[j], ax=ax, fraction=0.5, aspect=5)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"{fname}.png\", dpi=300)\n",
    "        \n",
    "    return fig, axs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensorboard writer\n",
    "writer = SummaryWriter(dir_runs)\n",
    "metrics = {\n",
    "    \"epoch\": [],\n",
    "    \"Loss/train\": [], \n",
    "    \"Loss/train_recons\": [],\n",
    "    \"Loss/train_kld\": [],\n",
    "    \"Loss/val\": [],\n",
    "    \"Loss/val_recons\": [],\n",
    "    \"Loss/val_kld\": []\n",
    "}\n",
    "fname = f\"{dir_models}/vae-{tag}\"\n",
    "print(f\"Tag: {tag}\")\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Epochs\", unit=\"epoch\", total=num_epochs, colour=\"green\"):\n",
    "    \n",
    "    # dump outputs\n",
    "    if epoch % num_epoch_dump == 0:\n",
    "        print(f\"Writing data for epoch {epoch} of {num_epochs}\")\n",
    "        plot_ae_outputs(model, epoch, tag, n=6)\n",
    "        plot_latent(model, train_loader, epoch, tag)\n",
    "        torch.save(model.state_dict(), f\"{fname}-epoch_{epoch}.pt\")\n",
    "    \n",
    "    # train and test\n",
    "    train_loss, train_recons, train_kld = train_epoch(\n",
    "        vae=model,\n",
    "        device=device,\n",
    "        dataloader=train_loader,\n",
    "        optimizer=optim)\n",
    "    val_loss, val_recons, val_kld = test_epoch(\n",
    "        vae=model,\n",
    "        device=device,\n",
    "        dataloader=valid_loader, \n",
    "        verbose=True)\n",
    "\n",
    "    # log metrics\n",
    "    writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "    writer.add_scalar(\"Loss/train_recons\", train_recons, epoch)\n",
    "    writer.add_scalar(\"Loss/train_kld\", train_kld, epoch)\n",
    "    writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "    writer.add_scalar(\"Loss/val_recons\", val_recons, epoch)\n",
    "    writer.add_scalar(\"Loss/val_kld\", val_kld, epoch)\n",
    "    writer.flush()\n",
    "    metrics[\"epoch\"].append(epoch)\n",
    "    metrics[\"Loss/train\"].append(train_loss)\n",
    "    metrics[\"Loss/train_recons\"].append(train_recons)\n",
    "    metrics[\"Loss/train_kld\"].append(train_kld)\n",
    "    metrics[\"Loss/val\"].append(val_loss)\n",
    "    metrics[\"Loss/val_recons\"].append(val_recons)\n",
    "    metrics[\"Loss/val_kld\"].append(val_kld)\n",
    "\n",
    "print(\"Finished Training\")\n",
    "if epoch % num_epoch_dump != 0:\n",
    "    plot_ae_outputs(model, num_epochs, tag, n=6)\n",
    "    plot_latent(model, train_loader, num_epochs, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot final outputs\n",
    "plot_ae_outputs(model, num_epochs, tag, n=6)\n",
    "plot_latent(model, train_loader, num_epochs, tag)\n",
    "\n",
    "# save model\n",
    "torch.save(model.state_dict(), f\"{fname}-epoch_{num_epochs}.pt\")\n",
    "vae = model\n",
    "\n",
    "# save indices of all data sets\n",
    "np.savez_compressed(\n",
    "    f\"{dir_models}/indices-{tag}.npz\",\n",
    "    train=train_indices,\n",
    "    val=valid_indices\n",
    ")\n",
    "data_indices = {\"train\": train_indices, \"val\": valid_indices}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss curve\n",
    "fig, ax = plt.subplots()\n",
    "fname = f\"{dir_figures}/loss-{tag}\"\n",
    "\n",
    "ax.plot(range(num_epochs), metrics[\"Loss/train\"], label=\"Train\", linewidth=3)\n",
    "ax.plot(range(num_epochs), metrics[\"Loss/val\"], label=\"Validation\", linewidth=3)\n",
    "\n",
    "# convert y-axis to log scale\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_title(\"Loss Curve\", y=1.02)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{fname}.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot final latent space\n",
    "n_iter = 10000\n",
    "perplexities = [5, 10, 20, 30, 50, 80, 100, 200]\n",
    "\n",
    "for perplexity in perplexities:\n",
    "    tsne_tag = f\"tsne-perplexity_{perplexity}-n_iter_{n_iter}\"\n",
    "    out_tag = f\"{tsne_tag}-{tag}\"\n",
    "    fig, ax = plot_latent(vae, all_loader, num_epochs, out_tag, perplexity=perplexity, n_iter=n_iter)\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_all(datal: DataLoader, vae: Autoencoder, verbose: bool = False) -> np.ndarray:\n",
    "    # iterate over data loader to get all data\n",
    "    dat = []\n",
    "    for i, data in enumerate(datal):\n",
    "        dat.append(data)\n",
    "    dat = torch.cat(dat)\n",
    "    z = vae.encoder(dat.to(device))\n",
    "    z = z.to('cpu').detach().numpy()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Data shape: {z.shape}\")\n",
    "\n",
    "    return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_tsne(data: np.ndarray, perplexity: int = 30, n_iter: int = 10000, seed: int = 42, verbose: bool = False) -> tuple[np.ndarray, TSNE]:\n",
    "    # if number of columns is 2, return\n",
    "    if data.shape[1] == 2:\n",
    "        return data, None\n",
    "\n",
    "    # fit t-SNE\n",
    "    vout = 4 if verbose else 0\n",
    "    mod = TSNE(\n",
    "        n_components=2,\n",
    "        perplexity=perplexity,\n",
    "        n_iter=n_iter,\n",
    "        verbose=vout,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    z_red = mod.fit_transform(data)\n",
    "    if verbose:\n",
    "        print(f\"Final t-SNE KL divergence: {mod.kl_divergence_:.4f}\")\n",
    "        print(f\"Final t-SNE iterations: {mod.n_iter_+1}\")\n",
    "\n",
    "    return z_red, mod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode all data\n",
    "z_all = vae.encoder(dataset.to(device)).to('cpu').detach().numpy()\n",
    "print(f\"z_all shape: {z_all.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot probability distribution of latent space (iterate through each column)\n",
    "for i, z in enumerate(z_all.T):\n",
    "\n",
    "    # data analysis\n",
    "    kernel = stats.gaussian_kde(z)\n",
    "    z_range = np.linspace(z.min(), z.max(), 1000)\n",
    "    fes = -np.log(kernel(z_range))\n",
    "    fes -= np.nanmin(fes)\n",
    "\n",
    "    # figure\n",
    "    fname = f\"latent-prob-z_{i+1}\"\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(z_range, fes, linewidth=2.5, label=f\"$z_{i+1}$\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    ax.set_xlabel(f\"$z$\")\n",
    "    ax.set_ylabel(r\"$\\Delta F$ [$k_{B}\\, T$]\")\n",
    "    ax.set_title(\"Latent Space\", y=1.02)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"{dir_figures}/{fname}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the first and last latent space coordinates explain the most variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access data\n",
    "n_cols = z_all.shape[1]\n",
    "bandwidth = 0.05\n",
    "factor = 1.2\n",
    "for idx_x in range(n_cols):\n",
    "    for idx_y in range(idx_x + 1, n_cols):\n",
    "\n",
    "        x, y = z_all[:, idx_x], z_all[:, idx_y]\n",
    "        xmin, xmax = np.nanmin(x) * factor, np.nanmax(x) * factor\n",
    "        ymin, ymax = np.nanmin(y) * factor, np.nanmax(y) * factor\n",
    "\n",
    "        # calculate 2D KDE\n",
    "        xx, yy = np.mgrid[xmin:xmax:250j, ymin:ymax:250j]\n",
    "        positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "        values = np.vstack([x, y])\n",
    "        kernel = stats.gaussian_kde(values, bw_method=bandwidth/values.std())\n",
    "        pdf = kernel(positions).reshape(xx.shape)\n",
    "        pdf /= pdf.sum()\n",
    "\n",
    "        # figure\n",
    "        fname = f\"latent-pdf-z_{idx_x+1}-z_{idx_y+1}\"\n",
    "        fig, ax = plt.subplots()\n",
    "        im = ax.imshow(\n",
    "            pdf.T,\n",
    "            cmap=cmr.get_sub_cmap(\"cmr.rainforest\", 0.15, 0.96),\n",
    "            extent=[xmin, xmax, ymin, ymax],\n",
    "            origin=\"lower\",\n",
    "            aspect=\"auto\",\n",
    "        )\n",
    "        fig.colorbar(im, ax=ax, label=r\"Probability Density\")\n",
    "        ax.set_xlabel(f\"$z_{idx_x+1}$\")\n",
    "        ax.set_ylabel(f\"$z_{idx_y+1}$\")\n",
    "        ax.set_title(\"Latent Space\", y=1.02)\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(f\"{dir_figures}/{fname}.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access data\n",
    "n_cols = z_all.shape[1]\n",
    "factor = 1.2\n",
    "bandwidth = 0.05\n",
    "for idx_x in range(n_cols):\n",
    "    for idx_y in range(idx_x + 1, n_cols):\n",
    "\n",
    "        x, y = z_all[:, idx_x], z_all[:, idx_y]\n",
    "        xmin, xmax = np.nanmin(x) * factor, np.nanmax(x) * factor\n",
    "        ymin, ymax = np.nanmin(y) * factor, np.nanmax(y) * factor\n",
    "\n",
    "        # calculate 2D KDE\n",
    "        xx, yy = np.mgrid[xmin:xmax:250j, ymin:ymax:250j]\n",
    "        positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "        values = np.vstack([x, y])\n",
    "        kernel = stats.gaussian_kde(values, bw_method=bandwidth/values.std())\n",
    "        fes = -np.log(kernel(positions))\n",
    "        fes -= np.nanmin(fes)\n",
    "        # convert FES to 2D array\n",
    "        fes = fes.reshape(xx.shape)\n",
    "\n",
    "        # # calculate 2D histogram\n",
    "        # pdf, xx, yy = np.histogram2d(x, y, density=True, bins=100)\n",
    "        # fes = -np.log(pdf)\n",
    "        # fes -= np.nanmin(fes)\n",
    "\n",
    "        # figure\n",
    "        fname = f\"latent-fes-z_{idx_x+1}-z_{idx_y+1}\"\n",
    "        fig, ax = plt.subplots()\n",
    "        im = ax.imshow(\n",
    "            fes.T,\n",
    "            cmap=cmr.get_sub_cmap(\"cmr.rainforest_r\", 0.1, 0.80),\n",
    "            extent=[xmin, xmax, ymin, ymax],\n",
    "            origin=\"lower\",\n",
    "            aspect=\"auto\",\n",
    "            vmin=0,\n",
    "            vmax=6,\n",
    "        )\n",
    "        # add contours\n",
    "        levels = [1, 2, 3]\n",
    "        line_colors = [\"white\" for l in levels]\n",
    "        label_colors = [\"white\" for l in levels]\n",
    "        cp = ax.contour(xx, yy, fes, levels=levels, colors=line_colors, linewidths=1)\n",
    "        cl = ax.clabel(cp, fontsize=15, colors=label_colors)\n",
    "        # add colorbar\n",
    "        fig.colorbar(im, ax=ax, label=r\"$\\Delta F$ [$k_{B}\\, T$]\")\n",
    "        ax.set_xlabel(f\"$z_{idx_x+1}$\")\n",
    "        ax.set_ylabel(f\"$z_{idx_y+1}$\")\n",
    "        ax.set_title(\"Latent Space\", y=1.02)\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(f\"{dir_figures}/{fname}.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylabels = [f\"$z_{i+1}$\" for i in range(z_all.shape[1])]\n",
    "ydata = z_all.copy()\n",
    "print(f\"Shape of Y data: {ydata.shape}\")\n",
    "\n",
    "xcols = [\n",
    "    \"d12\",\n",
    "    \"Rg_0\",\n",
    "    \"Rg_1\"\n",
    "]\n",
    "xlabels = [\n",
    "    r\"$r_{12}$\",\n",
    "    r\"$R_{g, \\, 0}$\",\n",
    "    r\"$R_{g, \\, 1}$\",\n",
    "    r\"$\\sum CN{(\\mathrm{C}_{\\alpha})}$\",\n",
    "    r\"$\\sum CN{(\\mathrm{Ca})}$\",\n",
    "]\n",
    "\n",
    "xdata = features_unscaled[xcols].values.copy()\n",
    "# get sum of calpha coordination numbers\n",
    "cn_calpha = features_unscaled.filter(regex=\"CN_Calpha\").sum(axis=1)\n",
    "# get sum of calcium coordination numbers\n",
    "cn_ca = features_unscaled.filter(regex=\"CN_Ca\").sum(axis=1)\n",
    "# append columns to xdata\n",
    "xdata = np.hstack([xdata, cn_calpha.values.reshape(-1, 1), cn_ca.values.reshape(-1, 1)])\n",
    "print(f\"Shape of X data: {xdata.shape}\")\n",
    "\n",
    "wdata = dynamics[\"weight\"]\n",
    "print(f\"Shape of W data: {wdata.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot correlation between latent space and features\n",
    "figure = corner.corner(\n",
    "    ydata,\n",
    "    weights=wdata,\n",
    "    labels=ylabels,\n",
    "    quantiles=[0.25, 0.5, 0.75],\n",
    "    bins=20,\n",
    "    use_math_text=True,\n",
    "    show_titles=True,\n",
    "    title_kwargs={\"fontsize\": 12},\n",
    ")\n",
    "figure.savefig(f\"{dir_figures}/corner-latent.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot correlation between latent space and features\n",
    "figure = corner.corner(\n",
    "    xdata,\n",
    "    weights=wdata,\n",
    "    labels=xlabels,\n",
    "    quantiles=[0.25, 0.5, 0.75],\n",
    "    bins=20,\n",
    "    use_math_text=True,\n",
    "    show_titles=True,\n",
    "    title_kwargs={\"fontsize\": 12},\n",
    ")\n",
    "figure.savefig(f\"{dir_figures}/corner-features.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot correlation between latent space and features\n",
    "dat = np.hstack([ydata, xdata])\n",
    "labels = ylabels + xlabels\n",
    "\n",
    "figure = corner.corner(\n",
    "    dat,\n",
    "    weights=wdata,\n",
    "    labels=labels,\n",
    "    quantiles=[0.25, 0.5, 0.75],\n",
    "    bins=20,\n",
    "    use_math_text=True,\n",
    "    show_titles=True,\n",
    "    title_kwargs={\"fontsize\": 12},\n",
    ")\n",
    "figure.savefig(f\"{dir_figures}/corner-all.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot correlation matrix between latent space and features\n",
    "dat = np.hstack([ydata, xdata])\n",
    "labels = ylabels + xlabels\n",
    "df = pd.DataFrame(dat, columns=labels)\n",
    "\n",
    "# calculate correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# plot correlation matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=cmr.get_sub_cmap(\"cmr.fusion\", 0.1, 0.9),\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    ax=ax,\n",
    ")\n",
    "fig.savefig(f\"{dir_figures}/correlation-matrix.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot t-SNE colored by third variable\n",
    "col, col_label = \"d12\", r\"r$_{12}$ [nm]\"\n",
    "cmap = cmr.get_sub_cmap(\"cmr.rainforest\", 0.1, 0.9)\n",
    "\n",
    "for perplexity in perplexities:\n",
    "    tsne_tag = f\"tsne-perplexity_{perplexity}-n_iter_{n_iter}\"\n",
    "    fname = f\"{dir_figures}/tsne-{tag}-{tsne_tag}-colored_by_{col}\"\n",
    "\n",
    "    # fit t-SNE using all data\n",
    "    z_red, mod_tsne = fit_tsne(z_all, perplexity=perplexity, n_iter=n_iter, seed=seed, verbose=False)\n",
    "    df_t = pd.DataFrame(z_red, columns=[\"t-SNE 1\", \"t-SNE 2\"])\n",
    "    df_t.to_parquet(f\"{dir_models}/{tsne_tag}-{tag}.parquet\")\n",
    "\n",
    "    # merge all data\n",
    "    # df = pd.concat([features_unscaled, dynamics], axis=1)\n",
    "    df_t = pd.concat([df_d12, df_t], axis=1)\n",
    "\n",
    "    # gather data for plotting\n",
    "    x, y, z = df_t[\"t-SNE 1\"].copy(), df_t[\"t-SNE 2\"].copy(), df_t[col].copy()\n",
    "    if col == \"d12\":\n",
    "        z /= 10.\n",
    "\n",
    "    # create figure\n",
    "    fig, ax = plt.subplots()\n",
    "    sc = ax.scatter(x, y, c=z, cmap=cmap, s=5)\n",
    "    fig.colorbar(sc, ax=ax, shrink=0.9, fraction=0.1, pad=0.05, label=col_label)\n",
    "\n",
    "    # figure elements\n",
    "    ax.set_xlabel(r\"t-SNE 1\")\n",
    "    ax.set_ylabel(r\"t-SNE 2\")\n",
    "    ax.set_title(f\"t-SNE Colored by {col_label}\", y=1.02)\n",
    "\n",
    "    # save figure\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"{fname}.png\", dpi=300)\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot t-SNE colored by third variable\n",
    "col, col_label = \"rg_avg\", r\"$R_g$ [nm]\"\n",
    "cmap = cmr.get_sub_cmap(\"cmr.rainforest\", 0.1, 0.9)\n",
    "\n",
    "for perplexity in perplexities:\n",
    "    tsne_tag = f\"tsne-perplexity_{perplexity}-n_iter_{n_iter}\"\n",
    "    fname = f\"{dir_figures}/tsne-{tag}-{tsne_tag}-colored_by_{col}\"\n",
    "\n",
    "    # fit t-SNE using all data\n",
    "    z_red, mod_tsne = fit_tsne(z_all, perplexity=perplexity, n_iter=n_iter, seed=seed, verbose=False)\n",
    "    df_t = pd.DataFrame(z_red, columns=[\"t-SNE 1\", \"t-SNE 2\"])\n",
    "    df_t.to_parquet(f\"{dir_models}/{tsne_tag}-{tag}.parquet\")\n",
    "\n",
    "    # merge all data\n",
    "    df = pd.concat([features_unscaled, dynamics], axis=1)\n",
    "    df_t = pd.concat([df, df_t], axis=1)\n",
    "\n",
    "    # gather data for plotting\n",
    "    x, y = df_t[\"t-SNE 1\"].copy(), df_t[\"t-SNE 2\"].copy()\n",
    "    z = (df_t[\"Rg_0\"] + df_t[\"Rg_1\"]) / 2.\n",
    "\n",
    "    # create figure\n",
    "    fig, ax = plt.subplots()\n",
    "    sc = ax.scatter(x, y, c=z, cmap=cmap, s=5)\n",
    "    fig.colorbar(sc, ax=ax, shrink=0.9, fraction=0.1, pad=0.05, label=col_label)\n",
    "\n",
    "    # figure elements\n",
    "    ax.set_xlabel(r\"t-SNE 1\")\n",
    "    ax.set_ylabel(r\"t-SNE 2\")\n",
    "    ax.set_title(f\"t-SNE Colored by {col_label}\", y=1.02)\n",
    "\n",
    "    # save figure\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"{fname}.png\", dpi=300)\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
